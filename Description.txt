Steps to build the pipeline:
1. Creating a Github repository and cloning it in our local machine.
2. Adding a src folder in the local machine and then adding all the individual ML pipeline components in it for modular coding.

In this video we will mostly focus on building our ML pipeline, here is the basic layout:
Data Ingestion -> Data Preprocessing -> Feature Engineering -> Model Training -> Model Evaluation

We will use spacy to tokenize the string present in the text column of our dataset, we know that the data is present in english
language therefore we need to run this command in our environment first:
"python -m spacy download en_core_web_sm"
This will download the en core model for spacy.

3. Adding the data models and reports to the gitignore file.

Now we have added our modular coding files on github, the next step is:
4. Create dvc.yaml file and add stages to it.